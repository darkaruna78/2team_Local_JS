{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292edec3-8fc8-4767-8f90-2fcdf0d3284a",
   "metadata": {},
   "source": [
    "# ğŸï¸ Motorcycle Night Ride - ì•ˆì „ ì ìˆ˜ ì‚°ì¶œ í”„ë¡œì íŠ¸\n",
    "\n",
    "## í”„ë¡œì íŠ¸ ê°œìš”\n",
    "- **ë°ì´í„°ì…‹**: Acme AI Open Dataset - Motorcycle Night Ride (ì•¼ê°„ ì˜¤í† ë°”ì´ ì£¼í–‰, 200í”„ë ˆì„)\n",
    "- **ëª©í‘œ**: ì„¸ë§Œí‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ í”„ë ˆì„ë³„ **ì•ˆì „ ì ìˆ˜(Safety Score)** ì‚°ì¶œ\n",
    "- **6ê°œ í´ë˜ìŠ¤**: Undrivable, Road, Lanemark, My bike, Rider, Movable\n",
    "- **ë°©ë²•ë¡ **: ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ ì„¤ê³„ â†’ ML ëª¨ë¸ì„ í†µí•œ ì•ˆì „ ë“±ê¸‰ ë¶„ë¥˜\n",
    "\n",
    "### í‰ê°€ ê¸°ì¤€\n",
    "1. ë°ì´í„° EDAì™€ ì „ì²˜ë¦¬ê°€ ì ì ˆí•˜ê²Œ ì´ë¤„ì¡ŒëŠ”ê°€?\n",
    "2. Taskì— ì•Œë§ëŠ” ì ì ˆí•œ ëª¨ë¸ì„ ì„ ì •í–ˆëŠ”ê°€?\n",
    "3. ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ë…¼ë¦¬ì ìœ¼ë¡œ ì ‘ê·¼í–ˆëŠ”ê°€?\n",
    "4. ê²°ê³¼ ë„ì¶œì„ ìœ„í•´ ì—¬ëŸ¬ ê°€ì§€ ì‹œë„ë¥¼ ì§„í–‰í–ˆëŠ”ê°€?\n",
    "5. ë„ì¶œëœ ê²°ë¡ ì— ì¶©ë¶„í•œ ì„¤ë“ë ¥ì´ ìˆëŠ”ê°€?\n",
    "6. ì ì ˆí•œ metricì„ ì„¤ì •í•˜ê³  ê·¸ ì‚¬ìš© ê·¼ê±° ë° ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì˜€ëŠ”ê°€?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1ffaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "# ============================================================\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (macOS)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ì‹œê°í™” ìŠ¤íƒ€ì¼\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print('âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75727976",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. ë°ì´í„° EDA (íƒìƒ‰ì  ë°ì´í„° ë¶„ì„)\n",
    "\n",
    "ë°ì´í„°ì…‹ì˜ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê³ , ì´ë¯¸ì§€ì™€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ì˜ íŠ¹ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "- COCO JSON êµ¬ì¡° íƒìƒ‰ (images, annotations, categories)\n",
    "- ì´ë¯¸ì§€ íŒŒì¼ ë¶„ë¥˜ (ì›ë³¸ / fuse / mask)\n",
    "- í´ë˜ìŠ¤ë³„ ë¶„í¬ ë¶„ì„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677b1eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: ../www.acmeai.tech ODataset 1 - Motorcycle Night Ride Dataset\n",
      "ğŸ“ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: ../www.acmeai.tech ODataset 1 - Motorcycle Night Ride Dataset/images\n",
      "ğŸ“„ COCO JSON: ../www.acmeai.tech ODataset 1 - Motorcycle Night Ride Dataset/COCO_motorcycle (pixel).json\n",
      "\n",
      "==================================================\n",
      "ğŸ“Š ì „ì²´ íŒŒì¼ ìˆ˜: 600\n",
      "  - ì›ë³¸ ì´ë¯¸ì§€: 200ì¥\n",
      "  - Fuse ì´ë¯¸ì§€ (ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´): 200ì¥\n",
      "  - Mask ì´ë¯¸ì§€ (ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬): 200ì¥\n",
      "\n",
      "ğŸ“‹ ì´ë¯¸ì§€ ë„¤ì´ë° íŒ¨í„´:\n",
      "  - \"night ride (N).png\": 93ì¥\n",
      "  - \"Screenshot (N).png\": 107ì¥\n",
      "\n",
      "ğŸ“‹ ì›ë³¸ ì´ë¯¸ì§€ ì˜ˆì‹œ (ì²˜ìŒ 5ê°œ):\n",
      "  Screenshot (309).png\n",
      "  Screenshot (310).png\n",
      "  Screenshot (311).png\n",
      "  Screenshot (312).png\n",
      "  Screenshot (313).png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1-1. ë°ì´í„° ê²½ë¡œ ì„¤ì • ë° íŒŒì¼ êµ¬ì¡° íƒìƒ‰\n",
    "# ============================================================\n",
    "DATA_DIR = Path('..') / 'www.acmeai.tech ODataset 1 - Motorcycle Night Ride Dataset'\n",
    "IMAGE_DIR = DATA_DIR / 'images'\n",
    "JSON_PATH = DATA_DIR / 'COCO_motorcycle (pixel).json'\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ ë¶„ë¥˜\n",
    "all_files = sorted(os.listdir(IMAGE_DIR))\n",
    "original_files = [f for f in all_files if not f.endswith('___fuse.png') and not f.endswith('___save.png')]\n",
    "fuse_files = [f for f in all_files if f.endswith('___fuse.png')]\n",
    "mask_files = [f for f in all_files if f.endswith('___save.png')]\n",
    "\n",
    "print(f'ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}')\n",
    "print(f'ğŸ“ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {IMAGE_DIR}')\n",
    "print(f'ğŸ“„ COCO JSON: {JSON_PATH}')\n",
    "print(f'\\n{\"=\"*50}')\n",
    "print(f'ğŸ“Š ì „ì²´ íŒŒì¼ ìˆ˜: {len(all_files)}')\n",
    "print(f'  - ì›ë³¸ ì´ë¯¸ì§€: {len(original_files)}ì¥')\n",
    "print(f'  - Fuse ì´ë¯¸ì§€ (ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´): {len(fuse_files)}ì¥')\n",
    "print(f'  - Mask ì´ë¯¸ì§€ (ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬): {len(mask_files)}ì¥')\n",
    "\n",
    "# ì´ë¯¸ì§€ ë„¤ì´ë° íŒ¨í„´ ë¶„ì„\n",
    "night_ride = [f for f in original_files if f.startswith('night ride')]\n",
    "screenshot = [f for f in original_files if f.startswith('Screenshot')]\n",
    "print(f'\\nğŸ“‹ ì´ë¯¸ì§€ ë„¤ì´ë° íŒ¨í„´:')\n",
    "print(f'  - \"night ride (N).png\": {len(night_ride)}ì¥')\n",
    "print(f'  - \"Screenshot (N).png\": {len(screenshot)}ì¥')\n",
    "print(f'\\nğŸ“‹ ì›ë³¸ ì´ë¯¸ì§€ ì˜ˆì‹œ (ì²˜ìŒ 5ê°œ):')\n",
    "for f in original_files[:5]:\n",
    "    print(f'  {f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374800b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ COCO JSON ë¡œë”© ì¤‘... (200MB+ íŒŒì¼, ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n",
      "âœ… ë¡œë”© ì™„ë£Œ!\n",
      "\n",
      "ğŸ“‹ COCO JSON ìµœìƒìœ„ í‚¤: ['info', 'licenses', 'images', 'annotations', 'categories']\n",
      "\n",
      "ğŸ–¼ï¸  Images ìˆ˜: 200\n",
      "   í‚¤: ['id', 'file_name', 'height', 'width', 'license']\n",
      "   ì˜ˆì‹œ: {'id': 1, 'file_name': 'night ride (8).png', 'height': 1080, 'width': 1920, 'license': 1}\n",
      "\n",
      "ğŸ·ï¸  Categories ìˆ˜: 6\n",
      "   ID 1329681: Rider\n",
      "   ID 1323885: My bike\n",
      "   ID 1323884: Moveable\n",
      "   ID 1323882: Lane Mark\n",
      "   ID 1323881: Road\n",
      "   ID 1323880: Undrivable\n",
      "\n",
      "ğŸ“ Annotations ìˆ˜: 2305\n",
      "   í‚¤: ['id', 'image_id', 'segmentation', 'iscrowd', 'bbox', 'area', 'category_id']\n",
      "   Segmentation í˜•ì‹: Polygon (1 segments)\n",
      "\n",
      "ğŸ“– ì¹´í…Œê³ ë¦¬ ë§¤í•‘: {1329681: 'Rider', 1323885: 'My bike', 1323884: 'Moveable', 1323882: 'Lane Mark', 1323881: 'Road', 1323880: 'Undrivable'}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1-2. COCO JSON êµ¬ì¡° íƒìƒ‰\n",
    "# ============================================================\n",
    "print('â³ COCO JSON ë¡œë”© ì¤‘... (200MB+ íŒŒì¼, ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)')\n",
    "\n",
    "with open(JSON_PATH, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "print('âœ… ë¡œë”© ì™„ë£Œ!\\n')\n",
    "\n",
    "# ìµœìƒìœ„ í‚¤ êµ¬ì¡° í™•ì¸\n",
    "print(f'ğŸ“‹ COCO JSON ìµœìƒìœ„ í‚¤: {list(coco_data.keys())}')\n",
    "\n",
    "# images ì •ë³´\n",
    "images_info = coco_data.get('images', [])\n",
    "print(f'\\nğŸ–¼ï¸  Images ìˆ˜: {len(images_info)}')\n",
    "if images_info:\n",
    "    print(f'   í‚¤: {list(images_info[0].keys())}')\n",
    "    print(f'   ì˜ˆì‹œ: {images_info[0]}')\n",
    "\n",
    "# categories ì •ë³´\n",
    "categories_info = coco_data.get('categories', [])\n",
    "print(f'\\nğŸ·ï¸  Categories ìˆ˜: {len(categories_info)}')\n",
    "for cat in categories_info:\n",
    "    cid = cat['id']\n",
    "    cname = cat['name']\n",
    "    print(f'   ID {cid}: {cname}')\n",
    "\n",
    "# annotations ì •ë³´\n",
    "annotations_info = coco_data.get('annotations', [])\n",
    "print(f'\\nğŸ“ Annotations ìˆ˜: {len(annotations_info)}')\n",
    "if annotations_info:\n",
    "    print(f'   í‚¤: {list(annotations_info[0].keys())}')\n",
    "    seg = annotations_info[0].get('segmentation', None)\n",
    "    if seg:\n",
    "        if isinstance(seg, dict):\n",
    "            print(f'   Segmentation í˜•ì‹: RLE (Run Length Encoding)')\n",
    "            print(f'   RLE í‚¤: {list(seg.keys())}')\n",
    "        elif isinstance(seg, list):\n",
    "            print(f'   Segmentation í˜•ì‹: Polygon ({len(seg)} segments)')\n",
    "\n",
    "# ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "cat_id_to_name = {c['id']: c['name'] for c in categories_info}\n",
    "cat_name_to_id = {c['name']: c['id'] for c in categories_info}\n",
    "print(f'\\nğŸ“– ì¹´í…Œê³ ë¦¬ ë§¤í•‘: {cat_id_to_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1-3. ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™” (ì›ë³¸ / Fuse / Mask)\n",
    "# ============================================================\n",
    "sample_indices = [0, len(original_files) // 3, 2 * len(original_files) // 3]\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 16))\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    orig_name = original_files[idx]\n",
    "    fuse_name = orig_name + '___fuse.png'\n",
    "    mask_name = orig_name + '___save.png'\n",
    "\n",
    "    # ì›ë³¸ ì´ë¯¸ì§€\n",
    "    img_orig = Image.open(IMAGE_DIR / orig_name)\n",
    "    axes[i, 0].imshow(img_orig)\n",
    "    axes[i, 0].set_title(f'ì›ë³¸: {orig_name}', fontsize=9)\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # Fuse ì´ë¯¸ì§€ (ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´)\n",
    "    if fuse_name in fuse_files:\n",
    "        img_fuse = Image.open(IMAGE_DIR / fuse_name)\n",
    "        axes[i, 1].imshow(img_fuse)\n",
    "    axes[i, 1].set_title('Fuse (ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´)', fontsize=9)\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "    # Mask ì´ë¯¸ì§€ (ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬)\n",
    "    if mask_name in mask_files:\n",
    "        img_mask = Image.open(IMAGE_DIR / mask_name)\n",
    "        axes[i, 2].imshow(img_mask)\n",
    "    axes[i, 2].set_title('Mask (ì„¸ê·¸ë©˜í…Œì´ì…˜)', fontsize=9)\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.suptitle('ìƒ˜í”Œ ì´ë¯¸ì§€: ì›ë³¸ / Fuse(ì˜¤ë²„ë ˆì´) / Mask(ì„¸ê·¸ë©˜í…Œì´ì…˜)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì´ë¯¸ì§€ í•´ìƒë„ í™•ì¸\n",
    "sample_img = Image.open(IMAGE_DIR / original_files[0])\n",
    "print(f'\\nğŸ“ ì´ë¯¸ì§€ í•´ìƒë„: {sample_img.size} (W x H)')\n",
    "print(f'   ì´ í”½ì…€ ìˆ˜: {sample_img.size[0] * sample_img.size[1]:,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e02d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1-4. COCO ì–´ë…¸í…Œì´ì…˜ ê¸°ë°˜ í´ë˜ìŠ¤ë³„ ë©´ì  ë¶„ì„\n",
    "# ============================================================\n",
    "images_df = pd.DataFrame(images_info)\n",
    "ann_df = pd.DataFrame(annotations_info)\n",
    "\n",
    "# imageë³„ ì´ í”½ì…€ ìˆ˜\n",
    "images_df['total_pixels'] = images_df['width'] * images_df['height']\n",
    "\n",
    "# annotationë³„ category name ì¶”ê°€\n",
    "ann_df['cat_name'] = ann_df['category_id'].map(cat_id_to_name)\n",
    "\n",
    "# ì´ë¯¸ì§€ë³„, ì¹´í…Œê³ ë¦¬ë³„ ë©´ì  í•©ê³„ (ë™ì¼ í´ë˜ìŠ¤ ë‚´ ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ ì²˜ë¦¬)\n",
    "area_by_cat = ann_df.groupby(['image_id', 'cat_name'])['area'].sum().reset_index()\n",
    "area_by_cat.columns = ['image_id', 'cat_name', 'total_area']\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë³„ í†µê³„\n",
    "class_stats = ann_df.groupby('cat_name')['area'].agg(['sum', 'mean', 'count']).reset_index()\n",
    "class_stats.columns = ['í´ë˜ìŠ¤', 'ì´ë©´ì ', 'í‰ê· ë©´ì ', 'ì–´ë…¸í…Œì´ì…˜ìˆ˜']\n",
    "class_stats = class_stats.sort_values('ì´ë©´ì ', ascending=False)\n",
    "\n",
    "print('ğŸ“Š í´ë˜ìŠ¤ë³„ ì–´ë…¸í…Œì´ì…˜ í†µê³„:')\n",
    "display(class_stats)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "colors_palette = sns.color_palette('Set2', len(class_stats))\n",
    "\n",
    "axes[0].barh(class_stats['í´ë˜ìŠ¤'], class_stats['ì´ë©´ì '], color=colors_palette)\n",
    "axes[0].set_xlabel('ì´ ë©´ì  (pixels)')\n",
    "axes[0].set_title('í´ë˜ìŠ¤ë³„ ì´ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë©´ì ')\n",
    "\n",
    "axes[1].barh(class_stats['í´ë˜ìŠ¤'], class_stats['ì–´ë…¸í…Œì´ì…˜ìˆ˜'], color=colors_palette)\n",
    "axes[1].set_xlabel('ì–´ë…¸í…Œì´ì…˜ ìˆ˜')\n",
    "axes[1].set_title('í´ë˜ìŠ¤ë³„ ì–´ë…¸í…Œì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nğŸ“Œ ë¶„ì„ í¬ì¸íŠ¸:')\n",
    "print('  - Road/Undrivable ë©´ì ì´ ê°€ì¥ í¼ â†’ ë„ë¡œ ì¥ë©´ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€')\n",
    "print('  - Movableì€ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ê°€ ë§ìŒ â†’ ë‹¤ì¤‘ ì°¨ëŸ‰/ë³´í–‰ì')\n",
    "print('  - Lanemark ë©´ì ì€ ì‘ì§€ë§Œ ì•ˆì „ì— ì¤‘ìš”í•œ feature')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ee0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1-5. ì´ë¯¸ì§€ë³„ í´ë˜ìŠ¤ ë¹„ìœ¨ ë¶„í¬ ë¶„ì„\n",
    "# ============================================================\n",
    "# pivot: image_id Ã— cat_name â†’ area\n",
    "pivot_area = area_by_cat.pivot_table(\n",
    "    index='image_id', columns='cat_name', values='total_area', fill_value=0\n",
    ")\n",
    "\n",
    "# ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ë¹„ìœ¨ ê³„ì‚°\n",
    "img_pixels = images_df.set_index('id')['total_pixels']\n",
    "pivot_ratio = pivot_area.div(img_pixels, axis=0)\n",
    "\n",
    "print('ğŸ“Š ì´ë¯¸ì§€ë³„ í´ë˜ìŠ¤ ë©´ì  ë¹„ìœ¨ í†µê³„:')\n",
    "display(pivot_ratio.describe().round(4))\n",
    "\n",
    "# ë°•ìŠ¤í”Œë¡¯\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "pivot_ratio.boxplot(ax=ax, vert=True, patch_artist=True,\n",
    "                    boxprops=dict(facecolor='lightblue'))\n",
    "ax.set_ylabel('ë©´ì  ë¹„ìœ¨')\n",
    "ax.set_title('ì´ë¯¸ì§€ë³„ í´ë˜ìŠ¤ ë©´ì  ë¹„ìœ¨ ë¶„í¬ (Boxplot)')\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# í•µì‹¬ í´ë˜ìŠ¤ íˆìŠ¤í† ê·¸ë¨\n",
    "key_classes = [c for c in ['Road', 'Movable', 'Undrivable'] if c in pivot_ratio.columns]\n",
    "if key_classes:\n",
    "    fig, axes = plt.subplots(1, len(key_classes), figsize=(6 * len(key_classes), 5))\n",
    "    if len(key_classes) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, col in zip(axes, key_classes):\n",
    "        pivot_ratio[col].hist(bins=20, ax=ax, color='steelblue', edgecolor='white')\n",
    "        ax.set_title(f'{col} ë¹„ìœ¨ ë¶„í¬')\n",
    "        ax.set_xlabel('ë¹„ìœ¨')\n",
    "        ax.set_ylabel('í”„ë ˆì„ ìˆ˜')\n",
    "    plt.suptitle('í•µì‹¬ í´ë˜ìŠ¤ ë¹„ìœ¨ ë¶„í¬', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e905b1c5",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "EDA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•ˆì „ ì ìˆ˜ ì‚°ì¶œì„ ìœ„í•œ **Feature DataFrame**ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "- ì´ë¯¸ì§€ë³„ 6ê°œ í´ë˜ìŠ¤ ë¹„ìœ¨ + Background ë¹„ìœ¨ â†’ Feature ë²¡í„°\n",
    "- ê²°ì¸¡ê°’ ì²˜ë¦¬ ë° Feature ê°„ ìƒê´€ê´€ê³„ ë¶„ì„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc819d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2-1. Feature DataFrame êµ¬ì¶•\n",
    "# ============================================================\n",
    "feature_df = pivot_ratio.copy().reset_index()\n",
    "\n",
    "# íŒŒì¼ëª… ë§¤í•‘\n",
    "id_to_filename = images_df.set_index('id')['file_name'].to_dict()\n",
    "feature_df['file_name'] = feature_df['image_id'].map(id_to_filename)\n",
    "\n",
    "# í´ë˜ìŠ¤ ì»¬ëŸ¼ ì‹ë³„\n",
    "class_columns = [c for c in feature_df.columns if c not in ['image_id', 'file_name']]\n",
    "\n",
    "# ê²°ì¸¡ê°’ ì²˜ë¦¬ (ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” í´ë˜ìŠ¤ â†’ 0)\n",
    "feature_df[class_columns] = feature_df[class_columns].fillna(0)\n",
    "\n",
    "# Background ë¹„ìœ¨ ì¶”ê°€ (1 - ëª¨ë“  í´ë˜ìŠ¤ ë¹„ìœ¨ í•©)\n",
    "feature_df['Background'] = (1 - feature_df[class_columns].sum(axis=1)).clip(lower=0)\n",
    "\n",
    "print(f'ğŸ“Š Feature DataFrame í˜•íƒœ: {feature_df.shape}')\n",
    "print(f'ğŸ“‹ ì»¬ëŸ¼: {list(feature_df.columns)}')\n",
    "print(f'\\nì²˜ìŒ 5í–‰:')\n",
    "display(feature_df.head())\n",
    "print(f'\\nê¸°ë³¸ í†µê³„:')\n",
    "display(feature_df[class_columns + ['Background']].describe().round(4))\n",
    "\n",
    "# ê²°ì¸¡ê°’ í™•ì¸\n",
    "missing = feature_df.isnull().sum()\n",
    "print(f'\\nğŸ“‹ ê²°ì¸¡ê°’ í™•ì¸:')\n",
    "print(missing[missing > 0] if missing.sum() > 0 else '  ê²°ì¸¡ê°’ ì—†ìŒ âœ…')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54143057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2-2. Feature ìƒê´€ê´€ê³„ ë¶„ì„\n",
    "# ============================================================\n",
    "corr_cols = class_columns + ['Background']\n",
    "corr_matrix = feature_df[corr_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            square=True, ax=ax, vmin=-1, vmax=1)\n",
    "ax.set_title('í´ë˜ìŠ¤ ë¹„ìœ¨ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('ğŸ“Œ ì£¼ìš” ìƒê´€ê´€ê³„ í•´ì„:')\n",
    "print('  - Road â†” Undrivable: ë°˜ë¹„ë¡€ â†’ ë„ë¡œê°€ ë„“ì„ìˆ˜ë¡ ë¹„ì£¼í–‰ì˜ì—­ì´ ì¢ë‹¤')\n",
    "print('  - Movable â†” Road: ì°¨ëŸ‰ì´ ë§ì„ìˆ˜ë¡ ë„ë¡œ ë©´ì ì— ì˜í–¥')\n",
    "print('  - Background ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ â†’ ë¼ë²¨ë§ë˜ì§€ ì•Šì€ ì˜ì—­(í•˜ëŠ˜, ì–´ë‘  ë“±)')\n",
    "print('  â‡’ Road, Undrivable, Movableì´ ì•ˆì „ ì ìˆ˜ì— í•µì‹¬ Featureê°€ ë  ê²ƒ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e517ab",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. ê·œì¹™ ê¸°ë°˜ ì•ˆì „ ì ìˆ˜ ì„¤ê³„\n",
    "\n",
    "ì„¸ë§Œí‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ì˜ í´ë˜ìŠ¤ë³„ ë¹„ìœ¨ì„ í™œìš©í•˜ì—¬ **ê·œì¹™ ê¸°ë°˜ ì•ˆì „ ì ìˆ˜**ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì„¤ê³„ ë…¼ë¦¬\n",
    "- **Road ë¹„ìœ¨ â†‘** â†’ ì „ë°© ë„ë¡œê°€ ë„“ê³  ëª…í™• â†’ **ì•ˆì „ë„ ì¦ê°€** (+0.35)\n",
    "- **Lanemark ë¹„ìœ¨ â†‘** â†’ ì°¨ì„ ì´ ì˜ ë³´ì„ â†’ **ì•ˆì „ë„ ì¦ê°€** (+0.15)\n",
    "- **Undrivable ë¹„ìœ¨ â†‘** â†’ ë¹„ì£¼í–‰ ì˜ì—­ì´ ê°€ê¹Œì›€ â†’ **ìœ„í—˜ë„ ì¦ê°€** (-0.25)\n",
    "- **Movable ë¹„ìœ¨ â†‘** â†’ ë‹¤ë¥¸ ì°¨ëŸ‰/ë³´í–‰ì ì¡´ì¬ â†’ **ìœ„í—˜ë„ ì¦ê°€** (-0.25)\n",
    "\n",
    "$$\\text{safety\\_raw} = 0.35 \\times \\text{Road} + 0.15 \\times \\text{Lanemark} - 0.25 \\times \\text{Undrivable} - 0.25 \\times \\text{Movable}$$\n",
    "\n",
    "â†’ MinMax ì •ê·œí™”í•˜ì—¬ **0~100** ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ í›„ 3ë“±ê¸‰ ë¶„ë¥˜:\n",
    "- **Safe** (â‰¥66) / **Caution** (33~66) / **Dangerous** (<33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea628ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-1. ì•ˆì „ ì ìˆ˜ ê³„ì‚°\n",
    "# ============================================================\n",
    "# ê°€ì¤‘ì¹˜ ì„¤ì •\n",
    "W_ROAD = 0.35\n",
    "W_LANEMARK = 0.15\n",
    "W_UNDRIVABLE = -0.25\n",
    "W_MOVABLE = -0.25\n",
    "\n",
    "def compute_safety_score(row, cols):\n",
    "    \"\"\"ê·œì¹™ ê¸°ë°˜ ì•ˆì „ ì ìˆ˜ ì‚°ì¶œ í•¨ìˆ˜\"\"\"\n",
    "    score = 0\n",
    "    if 'Road' in cols:\n",
    "        score += W_ROAD * row.get('Road', 0)\n",
    "    if 'Lanemark' in cols:\n",
    "        score += W_LANEMARK * row.get('Lanemark', 0)\n",
    "    if 'Undrivable' in cols:\n",
    "        score += W_UNDRIVABLE * row.get('Undrivable', 0)\n",
    "    if 'Movable' in cols:\n",
    "        score += W_MOVABLE * row.get('Movable', 0)\n",
    "    return score\n",
    "\n",
    "# ì›ì ìˆ˜ ê³„ì‚°\n",
    "feature_df['safety_raw'] = feature_df.apply(\n",
    "    lambda row: compute_safety_score(row, class_columns), axis=1\n",
    ")\n",
    "\n",
    "# MinMax ì •ê·œí™” â†’ 0~100\n",
    "s_min = feature_df['safety_raw'].min()\n",
    "s_max = feature_df['safety_raw'].max()\n",
    "feature_df['safety_score'] = (\n",
    "    (feature_df['safety_raw'] - s_min) / (s_max - s_min) * 100\n",
    ").round(1)\n",
    "\n",
    "# ì•ˆì „ ë“±ê¸‰ ë¶€ì—¬ (3ë“±ê¸‰)\n",
    "def assign_grade(score):\n",
    "    if score >= 66:\n",
    "        return 'Safe'\n",
    "    elif score >= 33:\n",
    "        return 'Caution'\n",
    "    else:\n",
    "        return 'Dangerous'\n",
    "\n",
    "feature_df['safety_grade'] = feature_df['safety_score'].apply(assign_grade)\n",
    "\n",
    "print('âœ… ì•ˆì „ ì ìˆ˜ ì‚°ì¶œ ì™„ë£Œ\\n')\n",
    "print(f'ğŸ“Š ì•ˆì „ ì ìˆ˜ ê¸°ë³¸ í†µê³„:')\n",
    "print(feature_df['safety_score'].describe().round(1))\n",
    "print(f'\\nğŸ“Š ì•ˆì „ ë“±ê¸‰ ë¶„í¬:')\n",
    "print(feature_df['safety_grade'].value_counts())\n",
    "print(f'\\nğŸ“‹ ê°€ì¤‘ì¹˜ ì„¤ì •:')\n",
    "print(f'  Road:       {W_ROAD:+.2f}')\n",
    "print(f'  Lanemark:   {W_LANEMARK:+.2f}')\n",
    "print(f'  Undrivable: {W_UNDRIVABLE:+.2f}')\n",
    "print(f'  Movable:    {W_MOVABLE:+.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-2. ì•ˆì „ ì ìˆ˜ ë¶„í¬ ì‹œê°í™”\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. íˆìŠ¤í† ê·¸ë¨\n",
    "axes[0].hist(feature_df['safety_score'], bins=20, color='steelblue', edgecolor='white')\n",
    "axes[0].axvline(33, color='red', linestyle='--', label='Dangerous/Caution ê²½ê³„')\n",
    "axes[0].axvline(66, color='green', linestyle='--', label='Caution/Safe ê²½ê³„')\n",
    "axes[0].set_xlabel('ì•ˆì „ ì ìˆ˜')\n",
    "axes[0].set_ylabel('í”„ë ˆì„ ìˆ˜')\n",
    "axes[0].set_title('ì•ˆì „ ì ìˆ˜ ë¶„í¬')\n",
    "axes[0].legend(fontsize=8)\n",
    "\n",
    "# 2. ë“±ê¸‰ë³„ íŒŒì´ì°¨íŠ¸\n",
    "grade_counts = feature_df['safety_grade'].value_counts()\n",
    "colors_pie = {'Safe': '#2ecc71', 'Caution': '#f39c12', 'Dangerous': '#e74c3c'}\n",
    "pie_colors = [colors_pie.get(g, 'gray') for g in grade_counts.index]\n",
    "axes[1].pie(grade_counts.values, labels=grade_counts.index, autopct='%1.1f%%',\n",
    "            colors=pie_colors, startangle=90)\n",
    "axes[1].set_title('ì•ˆì „ ë“±ê¸‰ ë¶„í¬')\n",
    "\n",
    "# 3. í”„ë ˆì„ ìˆœì„œë³„ ì•ˆì „ ì ìˆ˜ ì¶”ì´\n",
    "axes[2].plot(range(len(feature_df)), feature_df['safety_score'].values,\n",
    "             color='steelblue', alpha=0.7, linewidth=0.8)\n",
    "axes[2].axhline(33, color='red', linestyle='--', alpha=0.5)\n",
    "axes[2].axhline(66, color='green', linestyle='--', alpha=0.5)\n",
    "axes[2].fill_between(range(len(feature_df)), 0, 33, alpha=0.1, color='red')\n",
    "axes[2].fill_between(range(len(feature_df)), 33, 66, alpha=0.1, color='orange')\n",
    "axes[2].fill_between(range(len(feature_df)), 66, 100, alpha=0.1, color='green')\n",
    "axes[2].set_xlabel('í”„ë ˆì„ ë²ˆí˜¸')\n",
    "axes[2].set_ylabel('ì•ˆì „ ì ìˆ˜')\n",
    "axes[2].set_title('í”„ë ˆì„ë³„ ì•ˆì „ ì ìˆ˜ ì¶”ì´')\n",
    "\n",
    "plt.suptitle('ì•ˆì „ ì ìˆ˜ ë¶„ì„', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-3. ì•ˆì „/ìœ„í—˜ í”„ë ˆì„ ë¹„êµ ì‹œê°í™”\n",
    "# ============================================================\n",
    "safe_frames = feature_df.nlargest(3, 'safety_score')\n",
    "dangerous_frames = feature_df.nsmallest(3, 'safety_score')\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for i, (_, row) in enumerate(safe_frames.iterrows()):\n",
    "    fname = row['file_name']\n",
    "    fuse_path = IMAGE_DIR / (fname + '___fuse.png')\n",
    "    orig_path = IMAGE_DIR / fname\n",
    "    img_path = fuse_path if fuse_path.exists() else orig_path\n",
    "    if img_path.exists():\n",
    "        img = Image.open(img_path)\n",
    "        axes[0, i].imshow(img)\n",
    "    score_val = row['safety_score']\n",
    "    axes[0, i].set_title(f'Safe: {score_val}ì \\n{fname}', fontsize=9, color='green')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "for i, (_, row) in enumerate(dangerous_frames.iterrows()):\n",
    "    fname = row['file_name']\n",
    "    fuse_path = IMAGE_DIR / (fname + '___fuse.png')\n",
    "    orig_path = IMAGE_DIR / fname\n",
    "    img_path = fuse_path if fuse_path.exists() else orig_path\n",
    "    if img_path.exists():\n",
    "        img = Image.open(img_path)\n",
    "        axes[1, i].imshow(img)\n",
    "    score_val = row['safety_score']\n",
    "    axes[1, i].set_title(f'Dangerous: {score_val}ì \\n{fname}', fontsize=9, color='red')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('ğŸŸ¢ Safe', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('ğŸ”´ Dangerous', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('ì•ˆì „ ë“±ê¸‰ë³„ í”„ë ˆì„ ë¹„êµ (ìƒìœ„ 3 vs í•˜ìœ„ 3)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('ğŸ“Œ í•´ì„:')\n",
    "print('  - Safe í”„ë ˆì„: ë„“ì€ ë„ë¡œ, ì ì€ ì¥ì• ë¬¼, ëª…í™•í•œ ì°¨ì„ ')\n",
    "print('  - Dangerous í”„ë ˆì„: ì¢ì€ ë„ë¡œ, ë§ì€ ì°¨ëŸ‰/ë³´í–‰ì, ë¹„ì£¼í–‰ ì˜ì—­ ì¦ê°€')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e1a96",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. ëª¨ë¸ ì„ ì • ë° í•™ìŠµ\n",
    "\n",
    "### ëª¨ë¸ ì„ ì • ê·¼ê±°\n",
    "- ë°ì´í„° ìˆ˜ê°€ ì•½ 200ì¥ìœ¼ë¡œ ì ìœ¼ë¯€ë¡œ ê³ ìš©ëŸ‰ ë”¥ëŸ¬ë‹ ëª¨ë¸ ëŒ€ì‹  í•´ì„ ê°€ëŠ¥í•œ í”¼ì²˜ ê¸°ë°˜ ëª¨ë¸ ì„ íƒ\n",
    "- ì„¸ê·¸ë©˜í…Œì´ì…˜ì€ ì´ë¯¸ ì œê³µëœ ë¼ë²¨ì„ í™œìš©í•˜ì—¬ downstream task (ì•ˆì „ ë“±ê¸‰ ë¶„ë¥˜)ì— ì§‘ì¤‘\n",
    "- ì•ˆì „ ì ìˆ˜ëŠ” ì„¤ëª…ë ¥ì´ ì¤‘ìš”í•˜ë¯€ë¡œ Feature Importanceë¥¼ ë³¼ ìˆ˜ ìˆëŠ” ëª¨ë¸ ìœ ë¦¬\n",
    "\n",
    "### ì‹¤í—˜ ê³„íš\n",
    "- **ì‹¤í—˜ 1**: Logistic Regression (Baseline, ì„ í˜• ëª¨ë¸)\n",
    "- **ì‹¤í—˜ 2**: Random Forest (ë¹„ì„ í˜•, ì•™ìƒë¸”, Feature Importance)\n",
    "- **ì‹¤í—˜ 3**: Gradient Boosting (ë¶€ìŠ¤íŒ… ê¸°ë°˜, ë†’ì€ ì„±ëŠ¥ ê¸°ëŒ€)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d85209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ì‹¤í—˜ 1: Logistic Regression (Baseline)\n",
    "# ============================================================\n",
    "# Feature / Target ì¤€ë¹„\n",
    "feature_cols = [c for c in class_columns if c in feature_df.columns] + ['Background']\n",
    "X = feature_df[feature_cols].values\n",
    "y = feature_df['safety_grade'].values\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(f'ğŸ“‹ í´ë˜ìŠ¤: {list(le.classes_)}')\n",
    "print(f'ğŸ“Š ë°ì´í„° shape: X={X.shape}, y={y_encoded.shape}')\n",
    "\n",
    "# Train/Test Split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "print(f'   Train: {X_train.shape[0]}ê°œ, Test: {X_test.shape[0]}ê°œ')\n",
    "\n",
    "# StandardScaler (Logistic Regressionìš©)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "lr_f1 = f1_score(y_test, lr_pred, average='macro')\n",
    "\n",
    "print(f'\\nğŸ”¬ ì‹¤í—˜ 1: Logistic Regression')\n",
    "print(f'   Accuracy: {lr_acc:.4f}')\n",
    "print(f'   Macro F1: {lr_f1:.4f}')\n",
    "print(f'\\n{classification_report(y_test, lr_pred, target_names=le.classes_)}')\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "results = []\n",
    "results.append({\n",
    "    'Model': 'Logistic Regression', 'Accuracy': lr_acc,\n",
    "    'Macro_F1': lr_f1, 'Features': 'Basic'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ì‹¤í—˜ 2: Random Forest\n",
    "# ============================================================\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=5, random_state=42, class_weight='balanced'\n",
    ")\n",
    "rf_model.fit(X_train, y_train)  # RFëŠ” ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred, average='macro')\n",
    "\n",
    "print(f'ğŸ”¬ ì‹¤í—˜ 2: Random Forest')\n",
    "print(f'   Accuracy: {rf_acc:.4f}')\n",
    "print(f'   Macro F1: {rf_f1:.4f}')\n",
    "print(f'\\n{classification_report(y_test, rf_pred, target_names=le.classes_)}')\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Random Forest', 'Accuracy': rf_acc,\n",
    "    'Macro_F1': rf_f1, 'Features': 'Basic'\n",
    "})\n",
    "\n",
    "# Feature Importance (ì´ˆê¸° í™•ì¸)\n",
    "feat_imp = pd.Series(rf_model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(f'\\nğŸ“Š Random Forest Feature Importance:')\n",
    "for fname, imp in feat_imp.items():\n",
    "    bar = 'â–ˆ' * int(imp * 50)\n",
    "    print(f'   {fname:>15s}: {imp:.4f} {bar}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1049ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ì‹¤í—˜ 3: Gradient Boosting\n",
    "# ============================================================\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "gb_f1 = f1_score(y_test, gb_pred, average='macro')\n",
    "\n",
    "print(f'ğŸ”¬ ì‹¤í—˜ 3: Gradient Boosting')\n",
    "print(f'   Accuracy: {gb_acc:.4f}')\n",
    "print(f'   Macro F1: {gb_f1:.4f}')\n",
    "print(f'\\n{classification_report(y_test, gb_pred, target_names=le.classes_)}')\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Gradient Boosting', 'Accuracy': gb_acc,\n",
    "    'Macro_F1': gb_f1, 'Features': 'Basic'\n",
    "})\n",
    "\n",
    "# ì‹¤í—˜ 1~3 ë¹„êµ\n",
    "results_df = pd.DataFrame(results)\n",
    "print('\\nğŸ“Š ì‹¤í—˜ 1~3 ê²°ê³¼ ë¹„êµ:')\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee0754",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. ì„±ëŠ¥ í–¥ìƒ\n",
    "\n",
    "ë…¼ë¦¬ì ì´ê³  ë‹¨ê³„ì ì¸ ì ‘ê·¼ìœ¼ë¡œ ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì ‘ê·¼ ì „ëµ\n",
    "1. **íŒŒìƒ Feature ì¶”ê°€**: ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ì˜ ë³µí•© Feature ìƒì„±\n",
    "   - Road vs Undrivable ì°¨ì´, Movable/Road ë°€ë„, ì£¼í–‰ê°€ëŠ¥ë¹„ìœ¨, ìœ„í—˜ìš”ì†Œ ì´í•©\n",
    "2. **K-Fold Cross Validation**: 200ì¥ì˜ ì ì€ ë°ì´í„°ì—ì„œ ì•ˆì •ì  í‰ê°€\n",
    "3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: GridSearchCVë¡œ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bda7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5-1. íŒŒìƒ Feature ì¶”ê°€ + ì‹¤í—˜ 4\n",
    "# ============================================================\n",
    "feature_df_adv = feature_df.copy()\n",
    "\n",
    "# 1. Road vs Undrivable ë¹„ìœ¨ ì°¨ì´ (ë„ë¡œ ìš°ì„¸ ì •ë„)\n",
    "if 'Road' in feature_df_adv.columns and 'Undrivable' in feature_df_adv.columns:\n",
    "    feature_df_adv['road_undrivable_diff'] = feature_df_adv['Road'] - feature_df_adv['Undrivable']\n",
    "\n",
    "# 2. Movable/Road ë¹„ìœ¨ (ë„ë¡œ ìœ„ ì°¨ëŸ‰ ë°€ë„ ëŒ€ë¦¬ì§€í‘œ)\n",
    "if 'Road' in feature_df_adv.columns and 'Movable' in feature_df_adv.columns:\n",
    "    feature_df_adv['movable_road_ratio'] = feature_df_adv['Movable'] / (feature_df_adv['Road'] + 1e-6)\n",
    "\n",
    "# 3. Lanemark/Road ë¹„ìœ¨ (ì°¨ì„  ê°€ì‹œì„±)\n",
    "if 'Road' in feature_df_adv.columns and 'Lanemark' in feature_df_adv.columns:\n",
    "    feature_df_adv['lanemark_road_ratio'] = feature_df_adv['Lanemark'] / (feature_df_adv['Road'] + 1e-6)\n",
    "\n",
    "# 4. ì£¼í–‰ ê°€ëŠ¥ ì˜ì—­ ë¹„ìœ¨ (Road + Lanemark)\n",
    "drivable = feature_df_adv.get('Road', 0)\n",
    "if 'Lanemark' in feature_df_adv.columns:\n",
    "    drivable = drivable + feature_df_adv['Lanemark']\n",
    "feature_df_adv['drivable_ratio'] = drivable\n",
    "\n",
    "# 5. ìœ„í—˜ ìš”ì†Œ ì´í•© (Undrivable + Movable)\n",
    "hazard = 0\n",
    "if 'Undrivable' in feature_df_adv.columns:\n",
    "    hazard = hazard + feature_df_adv['Undrivable']\n",
    "if 'Movable' in feature_df_adv.columns:\n",
    "    hazard = hazard + feature_df_adv['Movable']\n",
    "feature_df_adv['hazard_ratio'] = hazard\n",
    "\n",
    "# ì¶”ê°€ëœ Feature í™•ì¸\n",
    "adv_feature_cols = feature_cols + [\n",
    "    'road_undrivable_diff', 'movable_road_ratio',\n",
    "    'lanemark_road_ratio', 'drivable_ratio', 'hazard_ratio'\n",
    "]\n",
    "adv_feature_cols = [c for c in adv_feature_cols if c in feature_df_adv.columns]\n",
    "\n",
    "print(f'ğŸ“Š ê¸°ì¡´ Feature ìˆ˜: {len(feature_cols)}')\n",
    "print(f'ğŸ“Š ì¶”ê°€ Feature ìˆ˜: {len(adv_feature_cols) - len(feature_cols)}')\n",
    "print(f'ğŸ“Š ì´ Feature ìˆ˜: {len(adv_feature_cols)}')\n",
    "new_feats = [c for c in adv_feature_cols if c not in feature_cols]\n",
    "print(f'\\nì¶”ê°€ëœ Feature: {new_feats}')\n",
    "\n",
    "# ìƒˆë¡œìš´ Featureë¡œ ë°ì´í„° ì¤€ë¹„\n",
    "X_adv = feature_df_adv[adv_feature_cols].values\n",
    "X_train_adv, X_test_adv, y_train_adv, y_test_adv = train_test_split(\n",
    "    X_adv, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Random Forest + íŒŒìƒ Feature\n",
    "rf_adv = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=5, random_state=42, class_weight='balanced'\n",
    ")\n",
    "rf_adv.fit(X_train_adv, y_train_adv)\n",
    "rf_adv_pred = rf_adv.predict(X_test_adv)\n",
    "\n",
    "rf_adv_acc = accuracy_score(y_test_adv, rf_adv_pred)\n",
    "rf_adv_f1 = f1_score(y_test_adv, rf_adv_pred, average='macro')\n",
    "\n",
    "print(f'\\nğŸ”¬ ì‹¤í—˜ 4: Random Forest + íŒŒìƒ Feature')\n",
    "print(f'   Accuracy: {rf_adv_acc:.4f}  (ê¸°ì¡´ RF: {rf_acc:.4f})')\n",
    "print(f'   Macro F1: {rf_adv_f1:.4f}  (ê¸°ì¡´ RF: {rf_f1:.4f})')\n",
    "\n",
    "results.append({\n",
    "    'Model': 'RF + Advanced Features', 'Accuracy': rf_adv_acc,\n",
    "    'Macro_F1': rf_adv_f1, 'Features': 'Advanced'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aec627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5-2. K-Fold Cross Validation ë¹„êµ\n",
    "# ============================================================\n",
    "# ë°ì´í„°ê°€ ~200ì¥ìœ¼ë¡œ ì ìœ¼ë¯€ë¡œ 5-Fold CVë¡œ ì•ˆì •ì  í‰ê°€\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models_cv = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000, random_state=42, class_weight='balanced'\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=5, random_state=42, class_weight='balanced'\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42\n",
    "    ),\n",
    "}\n",
    "\n",
    "print('ğŸ“Š 5-Fold Cross Validation ê²°ê³¼ (Advanced Features ì‚¬ìš©):\\n')\n",
    "cv_results = {}\n",
    "scaler_cv = StandardScaler()\n",
    "\n",
    "for name, model in models_cv.items():\n",
    "    # Logistic Regressionë§Œ ìŠ¤ì¼€ì¼ë§ ì ìš©\n",
    "    if 'Logistic' in name:\n",
    "        X_cv = scaler_cv.fit_transform(X_adv)\n",
    "    else:\n",
    "        X_cv = X_adv\n",
    "\n",
    "    scores_acc = cross_val_score(model, X_cv, y_encoded, cv=cv, scoring='accuracy')\n",
    "    scores_f1 = cross_val_score(model, X_cv, y_encoded, cv=cv, scoring='f1_macro')\n",
    "\n",
    "    cv_results[name] = {\n",
    "        'Acc_mean': scores_acc.mean(),\n",
    "        'Acc_std': scores_acc.std(),\n",
    "        'F1_mean': scores_f1.mean(),\n",
    "        'F1_std': scores_f1.std()\n",
    "    }\n",
    "    print(f'  {name}:')\n",
    "    print(f'    Accuracy: {scores_acc.mean():.4f} +/- {scores_acc.std():.4f}')\n",
    "    print(f'    Macro F1: {scores_f1.mean():.4f} +/- {scores_f1.std():.4f}')\n",
    "    print()\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results).T\n",
    "print('ğŸ“Š CV ê²°ê³¼ ìš”ì•½:')\n",
    "display(cv_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d29736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5-3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (GridSearchCV)\n",
    "# ============================================================\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print('â³ GridSearchCV ì§„í–‰ ì¤‘...')\n",
    "grid_search.fit(X_adv, y_encoded)\n",
    "\n",
    "print(f'ğŸ† ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {grid_search.best_params_}')\n",
    "print(f'ğŸ† ìµœì  Macro F1 (CV): {grid_search.best_score_:.4f}')\n",
    "\n",
    "# ìµœì  ëª¨ë¸ë¡œ ìµœì¢… í‰ê°€\n",
    "best_model = grid_search.best_estimator_\n",
    "best_pred = best_model.predict(X_test_adv)\n",
    "best_acc = accuracy_score(y_test_adv, best_pred)\n",
    "best_f1 = f1_score(y_test_adv, best_pred, average='macro')\n",
    "\n",
    "print(f'\\nğŸ“Š ìµœì  ëª¨ë¸ Test ì„±ëŠ¥:')\n",
    "print(f'   Accuracy: {best_acc:.4f}')\n",
    "print(f'   Macro F1: {best_f1:.4f}')\n",
    "\n",
    "results.append({\n",
    "    'Model': 'RF Tuned + Advanced', 'Accuracy': best_acc,\n",
    "    'Macro_F1': best_f1, 'Features': 'Advanced+Tuned'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c4a6b",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. ê²°ê³¼ ë¶„ì„ ë° Metric í‰ê°€\n",
    "\n",
    "### Metric ì„ ì • ê·¼ê±°\n",
    "- **Accuracy**: ì „ë°˜ì  ì •í™•ë„ (ì§ê´€ì ì´ë‚˜, í´ë˜ìŠ¤ ë¶ˆê· í˜•ì— ì·¨ì•½)\n",
    "- **Macro F1-Score** (ì£¼ìš” metric): ê° ë“±ê¸‰ì„ ë™ë“±í•˜ê²Œ í‰ê°€. ì•ˆì „ ì‹œìŠ¤í…œì—ì„œ ëª¨ë“  ë“±ê¸‰ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ì±„íƒ\n",
    "- **Confusion Matrix**: \"Dangerousë¥¼ Safeë¡œ ì˜¤ë¶„ë¥˜\"í•˜ëŠ” ì¹˜ëª…ì  ì˜¤ë¥˜ë¥¼ í™•ì¸í•´ì•¼ í•¨\n",
    "  - ì‹¤ì œ ì•ˆì „ ì‹œìŠ¤í…œì—ì„œëŠ” ìœ„í—˜ í”„ë ˆì„ì„ ë†“ì¹˜ë©´ ì‚¬ê³  ìœ„í—˜ ì¦ê°€ -> Recallì´ ì¤‘ìš”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f86347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6-1. ì „ì²´ ì‹¤í—˜ ê²°ê³¼ ë¹„êµ + Feature Importance\n",
    "# ============================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "print('ğŸ“Š ì „ì²´ ì‹¤í—˜ ê²°ê³¼ ë¹„êµ:')\n",
    "display(results_df.sort_values('Macro_F1', ascending=False))\n",
    "\n",
    "# ëª¨ë¸ë³„ ì„±ëŠ¥ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "x_pos = range(len(results_df))\n",
    "axes[0].bar(x_pos, results_df['Accuracy'], color='steelblue', alpha=0.8)\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(results_df['Model'], rotation=25, ha='right', fontsize=9)\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('ëª¨ë¸ë³„ Accuracy ë¹„êµ')\n",
    "axes[0].set_ylim(0, 1.05)\n",
    "for i, v in enumerate(results_df['Accuracy']):\n",
    "    axes[0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=8)\n",
    "\n",
    "axes[1].bar(x_pos, results_df['Macro_F1'], color='coral', alpha=0.8)\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(results_df['Model'], rotation=25, ha='right', fontsize=9)\n",
    "axes[1].set_ylabel('Macro F1-Score')\n",
    "axes[1].set_title('ëª¨ë¸ë³„ Macro F1 ë¹„êµ')\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "for i, v in enumerate(results_df['Macro_F1']):\n",
    "    axes[1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=8)\n",
    "\n",
    "plt.suptitle('ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance (ìµœì  ëª¨ë¸)\n",
    "feat_imp_final = pd.Series(\n",
    "    best_model.feature_importances_, index=adv_feature_cols\n",
    ").sort_values(ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "feat_imp_final.plot(kind='barh', ax=ax, color='teal')\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title('ìµœì  ëª¨ë¸ Feature Importance (RF Tuned)', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nğŸ“Œ Feature Importance í•´ì„:')\n",
    "top3 = feat_imp_final.nlargest(3)\n",
    "for fname, imp in top3.items():\n",
    "    print(f'   {fname}: {imp:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6-2. Confusion Matrix & Classification Report\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ìµœì  ëª¨ë¸ (RF Tuned + Advanced)\n",
    "cm_best = confusion_matrix(y_test_adv, best_pred)\n",
    "disp_best = ConfusionMatrixDisplay(cm_best, display_labels=le.classes_)\n",
    "disp_best.plot(ax=axes[0], cmap='Blues')\n",
    "axes[0].set_title('ìµœì  ëª¨ë¸ (RF Tuned + Advanced)')\n",
    "\n",
    "# Baseline (Logistic Regression) ë¹„êµ\n",
    "lr_adv = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "X_train_s = scaler.fit_transform(X_train_adv)\n",
    "X_test_s = scaler.transform(X_test_adv)\n",
    "lr_adv.fit(X_train_s, y_train_adv)\n",
    "lr_pred_adv = lr_adv.predict(X_test_s)\n",
    "\n",
    "cm_lr = confusion_matrix(y_test_adv, lr_pred_adv)\n",
    "disp_lr = ConfusionMatrixDisplay(cm_lr, display_labels=le.classes_)\n",
    "disp_lr.plot(ax=axes[1], cmap='Oranges')\n",
    "axes[1].set_title('Baseline (Logistic Regression)')\n",
    "\n",
    "plt.suptitle('Confusion Matrix ë¹„êµ', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nğŸ“‹ ìµœì  ëª¨ë¸ Classification Report:')\n",
    "print(classification_report(y_test_adv, best_pred, target_names=le.classes_))\n",
    "\n",
    "print('ğŸ“Œ Confusion Matrix í•´ì„:')\n",
    "print('  - ëŒ€ê°ì„ : ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ëœ ìƒ˜í”Œ ìˆ˜')\n",
    "print('  - Dangerousâ†’Safe ì˜¤ë¶„ë¥˜ (ì¢Œí•˜ë‹¨â†’ìš°ìƒë‹¨): ê°€ì¥ ìœ„í—˜í•œ ì˜¤ë¥˜')\n",
    "print('  - ìµœì  ëª¨ë¸ì—ì„œ ì´ëŸ° ì¹˜ëª…ì  ì˜¤ë¶„ë¥˜ê°€ ìµœì†Œí™”ë˜ì—ˆëŠ”ì§€ í™•ì¸')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d060387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6-3. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” (ëŒ€í‘œ í”„ë ˆì„)\n",
    "# ============================================================\n",
    "# ìµœì  ëª¨ë¸ë¡œ ì „ì²´ ë°ì´í„° ì˜ˆì¸¡\n",
    "all_pred = best_model.predict(X_adv)\n",
    "feature_df_adv['pred_grade'] = le.inverse_transform(all_pred)\n",
    "\n",
    "# ë“±ê¸‰ë³„ 2ì¥ì”© ìƒ˜í”Œ\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 16))\n",
    "grade_order = ['Safe', 'Caution', 'Dangerous']\n",
    "grade_colors = {'Safe': '#2ecc71', 'Caution': '#f39c12', 'Dangerous': '#e74c3c'}\n",
    "\n",
    "for gi, grade in enumerate(grade_order):\n",
    "    subset = feature_df_adv[feature_df_adv['pred_grade'] == grade]\n",
    "    n_samples = min(2, len(subset))\n",
    "    if n_samples == 0:\n",
    "        continue\n",
    "    samples = subset.sample(n=n_samples, random_state=42)\n",
    "\n",
    "    for si, (_, row) in enumerate(samples.iterrows()):\n",
    "        fname = row['file_name']\n",
    "        fuse_path = IMAGE_DIR / (fname + '___fuse.png')\n",
    "        orig_path = IMAGE_DIR / fname\n",
    "        img_path = fuse_path if fuse_path.exists() else orig_path\n",
    "        if img_path.exists():\n",
    "            img = Image.open(img_path)\n",
    "            axes[gi, si].imshow(img)\n",
    "        score_val = row['safety_score']\n",
    "        title = f'[{grade}] Score: {score_val}ì '\n",
    "        axes[gi, si].set_title(title, fontsize=11,\n",
    "                                color=grade_colors[grade], fontweight='bold')\n",
    "        axes[gi, si].axis('off')\n",
    "\n",
    "plt.suptitle('ì•ˆì „ ë“±ê¸‰ë³„ ëŒ€í‘œ í”„ë ˆì„ ì‹œê°í™” (ëª¨ë¸ ì˜ˆì¸¡ ê¸°ì¤€)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ë“±ê¸‰ ì¼ì¹˜ìœ¨\n",
    "match_rate = (feature_df_adv['safety_grade'] == feature_df_adv['pred_grade']).mean()\n",
    "print(f'\\nğŸ“Š ì „ì²´ ë°ì´í„° ë“±ê¸‰ ì¼ì¹˜ìœ¨ (ê·œì¹™ ê¸°ë°˜ vs ëª¨ë¸ ì˜ˆì¸¡): {match_rate:.1%}')\n",
    "\n",
    "# ë“±ê¸‰ë³„ í”„ë ˆì„ ìˆ˜\n",
    "print(f'\\nğŸ“Š ëª¨ë¸ ì˜ˆì¸¡ ë“±ê¸‰ ë¶„í¬:')\n",
    "print(feature_df_adv['pred_grade'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e8eb0",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. ê²°ë¡ \n",
    "\n",
    "## 7-1. í”„ë¡œì íŠ¸ ìš”ì•½\n",
    "- **ë°ì´í„°**: Motorcycle Night Ride ë°ì´í„°ì…‹ (ì•½ 200ì¥, 6í´ë˜ìŠ¤ ì„¸ë§Œí‹± ì„¸ê·¸ë©˜í…Œì´ì…˜)\n",
    "- **ëª©í‘œ**: ì„¸ê·¸ë©˜í…Œì´ì…˜ ì •ë³´ë¥¼ í™œìš©í•œ í”„ë ˆì„ë³„ ì•ˆì „ ì ìˆ˜ ì‚°ì¶œ\n",
    "- **ë°©ë²•**: ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ ì„¤ê³„ -> ML ëª¨ë¸ë¡œ ì•ˆì „ ë“±ê¸‰ ë¶„ë¥˜ (Safe / Caution / Dangerous)\n",
    "\n",
    "## 7-2. ì£¼ìš” ë°œê²¬\n",
    "1. **Road ë¹„ìœ¨ì´ ì•ˆì „ ì ìˆ˜ì— ê°€ì¥ í° ì˜í–¥** - ì „ë°© ë„ë¡œê°€ ë„“ê³  ëª…í™•í• ìˆ˜ë¡ ì•ˆì „\n",
    "2. **Movable(ì°¨ëŸ‰/ë³´í–‰ì) ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ ìœ„í—˜ë„ ì¦ê°€** - ì¥ì• ë¬¼ ì¡´ì¬ê°€ í•µì‹¬ ìœ„í—˜ ìš”ì†Œ\n",
    "3. **íŒŒìƒ Feature (road_undrivable_diff, hazard_ratio ë“±)ê°€ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬**\n",
    "4. **Random Forestê°€ ê°€ì¥ ì•ˆì •ì ì¸ ì„±ëŠ¥** - ì ì€ ë°ì´í„°ì—ì„œë„ ê°•ê±´í•˜ê³  í•´ì„ ê°€ëŠ¥\n",
    "\n",
    "## 7-3. Metric ì„ ì • ë° ê²°ê³¼ ë¶„ì„\n",
    "- **Macro F1-Score**: 3ê°œ ì•ˆì „ ë“±ê¸‰ì„ ë™ë“±í•˜ê²Œ ì¤‘ìš”ì‹œí•˜ê¸° ìœ„í•´ ì£¼ìš” metricìœ¼ë¡œ ì±„íƒ\n",
    "- **Confusion Matrix**: Dangerous->Safe ì˜¤ë¶„ë¥˜(ì¹˜ëª…ì  ì˜¤ë¥˜) ìµœì†Œí™” ì—¬ë¶€ í™•ì¸\n",
    "- ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ **5-Fold CV**ë¥¼ í™œìš©í•œ ì•ˆì •ì  ì„±ëŠ¥ í‰ê°€ ìˆ˜í–‰\n",
    "\n",
    "## 7-4. í•œê³„ ë° í–¥í›„ ê³¼ì œ\n",
    "- **ë°ì´í„° ìˆ˜ ë¶€ì¡± (ì•½ 200ì¥)**: ë³µì¡í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì ìš©ì´ ì–´ë ¤ì›€\n",
    "- **ì•¼ê°„ ì¥ë©´ë§Œ ì¡´ì¬**: ì£¼ê°„/ì•…ì²œí›„ ë“± ë‹¤ì–‘í•œ í™˜ê²½ìœ¼ë¡œ ì¼ë°˜í™” ë¶ˆê°€\n",
    "- **ë‹¨ì¼ í”„ë ˆì„ ê¸°ì¤€ í‰ê°€**: ì˜ìƒì˜ ì‹œê°„ì  ì—°ì†ì„±(temporal context) ë¯¸ë°˜ì˜\n",
    "- **í–¥í›„ ê°œì„  ë°©í–¥**:\n",
    "  - ROI(ê´€ì‹¬ì˜ì—­) ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ì „ë°© ë„ë¡œì— ë” ì§‘ì¤‘\n",
    "  - ì‹œê³„ì—´ ëª¨ë¸ë§ (ì—°ì† í”„ë ˆì„ ê°„ ì•ˆì „ ì ìˆ˜ ë³€í™” ì¶”ì )\n",
    "  - ë” í° ë°ì´í„°ì…‹ êµ¬ì¶• ë° ë”¥ëŸ¬ë‹ ëª¨ë¸ ì‹¤í—˜\n",
    "  - ì‹¤ì œ ì‚¬ê³ /ìœ„í—˜ ì´ë²¤íŠ¸ ë¼ë²¨ê³¼ì˜ ëŒ€ì¡° ê²€ì¦\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (motorcycle)",
   "language": "python",
   "name": "motorcycle-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
